# RAG Chatbot â€” Complete Setup Guide

A full-stack RAG (Retrieval-Augmented Generation) chatbot with FastAPI backend and Streamlit frontend.

## ğŸ“‹ Project Structure

```
RAG_chatbot/
â”œâ”€â”€ server/                    # FastAPI backend
â”‚   â”œâ”€â”€ app.py                # Main FastAPI app
â”‚   â”œâ”€â”€ vectorstore.py        # Vector indexing & querying (OpenAI embeddings + JSON store)
â”‚   â”œâ”€â”€ pdf_utils.py          # PDF extraction & chunking
â”‚   â”œâ”€â”€ requirements.txt       # Backend dependencies
â”‚   â”œâ”€â”€ README.md             # Backend docs
â”‚   â””â”€â”€ .env.example          # Backend env template
â”‚
â””â”€â”€ client/                    # Streamlit frontend
    â”œâ”€â”€ app.py                # Main Streamlit UI
    â”œâ”€â”€ requirements.txt       # Frontend dependencies
    â”œâ”€â”€ README.md             # Frontend docs
    â””â”€â”€ .env.example          # Frontend env template
```

## ğŸš€ Quick Start (Windows PowerShell)

### Prerequisites
- Python 3.8 or higher
- OpenAI API key ([get one here](https://platform.openai.com/api-keys))

### Step 1: Set Up Backend

```powershell
# Navigate to server folder
cd server

# Create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Create .env file with your OpenAI API key
# (or set it as an environment variable)
$env:OPENAI_API_KEY = 'sk-...'

# Start the backend server
uvicorn app:app --reload --port 8000
```

You should see:
```
INFO:     Uvicorn running on http://127.0.0.1:8000
```

**Keep this terminal open!** The server must run while you use the frontend.

### Step 2: Set Up Frontend (in a new terminal)

```powershell
# Navigate to client folder
cd client

# Create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Start Streamlit frontend
streamlit run app.py
```

Streamlit will open your default browser at `http://localhost:8501`.

---

## ğŸ“– Full Usage

### 1. Upload PDFs (Frontend)
- Open the Streamlit app (http://localhost:8501)
- Use the left sidebar to select up to 4 PDF files
- Click **"Upload & Index"**
- Wait for the status message (indexing takes ~30â€“60s depending on PDF size and OpenAI API)

### 2. Ask Questions (Frontend)
- Once documents are indexed, type a question
- Click **"Ask"**
- View the AI-generated answer with source citations

### 3. View Sources
- Expand **"ğŸ“– Sources"** to see which document chunks were used
- Chat history is preserved in the session

---

## ğŸ”§ Configuration

### Backend Configuration

**File:** `server/.env` (or environment variables)

```
OPENAI_API_KEY=sk-...  # Required: Your OpenAI API key
```

**Other settings (in `server/vectorstore.py`):**
- Embedding model: `text-embedding-3-small` (OpenAI)
- Chat model: `gpt-3.5-turbo` (OpenAI)
- Vector storage: JSON file (persisted to `server/data/chroma_db/`)
- Top-k retrieval: 4 documents

### Frontend Configuration

**File:** `client/.env` (optional)

```
BACKEND_URL=http://localhost:8000  # Backend address (default)
```

---

## ğŸ§ª Testing the API Directly

### Upload PDFs (via curl)

```powershell
curl -X POST "http://localhost:8000/upload" -F "files=@file1.pdf" -F "files=@file2.pdf"
```

**Response:**
```json
{
  "indexed_files": 2,
  "indexed_chunks": 145
}
```

### Ask a Question (via curl)

```powershell
curl -X POST "http://localhost:8000/query" `
  -H "Content-Type: application/json" `
  -d '{"question": "What is the main topic?"}'
```

**Response:**
```json
{
  "answer": "The main topic is...",
  "sources": [
    {
      "source": "file1.pdf",
      "page": 1,
      "snippet": "..."
    }
  ]
}
```

---

## ğŸ› Troubleshooting

### "ModuleNotFoundError" when starting backend
- Activate the virtual environment: `.\.venv\Scripts\Activate.ps1`
- Reinstall requirements: `pip install -r requirements.txt`

### "Could not connect to backend" in frontend
- Verify the backend is running: Check the backend terminal for "Uvicorn running"
- Check `BACKEND_URL` in `client/.env` matches your backend address
- If on different machines, update `BACKEND_URL` to the backend server's IP/hostname

### "No documents indexed yet"
- Upload PDFs first and wait for the success message in Streamlit

### Slow responses / API errors
- Check `OPENAI_API_KEY` is set correctly
- Verify your OpenAI account has API credits
- Check OpenAI API status at https://status.openai.com

### PDF not being recognized
- Ensure files are valid PDF files (not encrypted or corrupted)
- Try uploading one PDF at a time

---

## ğŸ“¦ Dependencies

### Backend
- **FastAPI** â€” Web framework
- **Uvicorn** â€” ASGI server
- **OpenAI** â€” Embeddings & Chat API
- **pypdf** â€” PDF text extraction
- **numpy** â€” Vector similarity computation
- **aiofiles, loguru, requests** â€” Utilities

### Frontend
- **Streamlit** â€” UI framework
- **Requests** â€” HTTP client for backend calls
- **python-dotenv** â€” Environment variable management

---

## ğŸ¯ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit  â”‚ (http://localhost:8501)             â”‚
â”‚  Frontend   â”‚                      â”‚              â”‚
â”‚  (browser)  â”‚                      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                      â”‚              â”‚
       â”‚                             â”‚              â”‚
       â”‚ POST /upload (PDF files)    â”‚              â”‚
       â”‚ POST /query (question)      â”‚              â”‚
       â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚              â”‚
       â”‚                             â”‚              â”‚
       â”‚     â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚ FastAPI     â”‚
       â”‚      (JSON response)        â”‚ Backend     â”‚
       â”‚                             â”‚ (localhost) â”‚
       â”‚                             â”‚              â”‚
       â”‚                             â”‚              â”‚
       â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
       â”‚                             â”‚ â”‚ PDF      â”‚â”‚
       â”‚                             â”‚ â”‚ Chunking â”‚â”‚
       â”‚                             â”‚ â”‚ & Split  â”‚â”‚
       â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
       â”‚                             â”‚              â”‚
       â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
       â”‚                             â”‚ â”‚ OpenAI   â”‚â”‚
       â”‚                             â”‚ â”‚Embeddingsâ”‚â”‚
       â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
       â”‚                             â”‚              â”‚
       â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
       â”‚                             â”‚ â”‚ Vector   â”‚â”‚
       â”‚                             â”‚ â”‚ Index    â”‚â”‚
       â”‚                             â”‚ â”‚(JSON)    â”‚â”‚
       â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
       â”‚                             â”‚              â”‚
       â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
       â”‚                             â”‚ â”‚ OpenAI   â”‚â”‚
       â”‚                             â”‚ â”‚ Chat     â”‚â”‚
       â”‚                             â”‚ â”‚(QA Gen)  â”‚â”‚
       â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
       â”‚                             â”‚              â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
                                                   â”‚
                    http://localhost:8000         â”‚
                                                   â”‚
                                                   â”‚
                    server/data/                   â”‚
                    â””â”€ chroma_db/                  â”‚
                       â””â”€ index.json (vectors)    â”‚
```

---

## ğŸ“ API Endpoints

### POST `/upload`
Upload PDF files to index.

**Request:** multipart/form-data with files
```
files: [file1.pdf, file2.pdf, ...]  (max 4)
```

**Response:** 200 OK
```json
{
  "indexed_files": 2,
  "indexed_chunks": 150
}
```

**Errors:**
- 400: More than 4 files, or non-PDF files provided
- 500: Indexing failed (check OPENAI_API_KEY)

### POST `/query`
Ask a question about the indexed documents.

**Request:** application/json
```json
{
  "question": "What is the main topic?"
}
```

**Response:** 200 OK
```json
{
  "answer": "The main topic is...",
  "sources": [
    {
      "source": "file1.pdf",
      "page": 1,
      "snippet": "The first page contains..."
    }
  ]
}
```

**Errors:**
- 400: Empty question
- 500: No documents indexed, or API error

---

## ğŸŒŸ Next Steps & Enhancements

- [ ] Add batch processing for large PDFs
- [ ] Support for different embedding models (Hugging Face, Azure)
- [ ] PostgreSQL vector DB instead of JSON (for scalability)
- [ ] Docker containerization for easy deployment
- [ ] User authentication & multi-tenant support
- [ ] PDF preview in Streamlit
- [ ] Export Q&A results to PDF
- [ ] Web-based admin dashboard for document management

---

## ğŸ“„ License

This project is provided as-is for educational and internal use.

---

## ğŸ¤ Support

For issues, check:
1. Backend logs: Check the terminal running `uvicorn`
2. Frontend logs: Check Streamlit terminal output
3. API responses: Use curl to test endpoints directly
4. Environment variables: Verify `OPENAI_API_KEY` is set

**Common Issues:**
- Backend not running: Start it with `uvicorn app:app --reload --port 8000`
- API key missing: Set `OPENAI_API_KEY` environment variable
- Connection refused: Ensure both services are running and on correct ports

---

**Made with â¤ï¸ â€” RAG Chatbot**
